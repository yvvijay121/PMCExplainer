## Inspiration
While working in various research laboratories and writing numerous literature reviews, I frequently encountered PubMed Central (PMC) articles. However, I found that these pages were often bare-bones, offering little additional context or explanation. Reading high-level medical research was challenging, and I struggled to fully grasp complex concepts without spending significant time deciphering the material. This frustration inspired me to create PMCExplainer—a tool designed to enhance comprehension by integrating AI-generated explanations directly into research articles.
## What it does
PMCExplainer allows users to input a PMCID, retrieve the full text of the research article, and interact with an AI-driven system that assesses their comprehension. The AI begins by analyzing the abstract and generating six questions that help determine the user's level of understanding. Based on the selected comprehension level (from 1 to 6), the model retrieves the full text and inserts AI-generated explanatory passages throughout the article. These passages help users better understand key concepts, connect minor details to the paper’s broader significance, and improve overall comprehension. For example, users who select level 3 receive explanations that highlight how smaller details contribute to the critical nature of the research.
## How we built it
The project relies on OpenAI’s API to generate structured outputs, including comprehension-based questions and explanatory blurbs. The system first retrieves the full text of the article from PMC, processes the abstract to generate assessment questions, and then inserts AI-generated explanations within the text based on the user’s comprehension level. The backend is responsible for handling data retrieval and AI interactions, while the front-end is still in development to create a seamless user experience.
## Challenges we ran into
One of the biggest challenges was front-end development. Since my expertise is primarily in research and AI integration, designing an intuitive and accessible user interface proved to be difficult. Additionally, structuring the AI-generated explanations in a way that feels natural and genuinely enhances comprehension required careful fine-tuning. Ensuring that the inserted blurbs are informative without disrupting the flow of the original research article was another key challenge.
## Accomplishments that we're proud of
We successfully developed a functional system that generates AI-driven explanations tailored to different levels of comprehension. Seeing the AI dynamically adjust its explanations based on user input was a major milestone. Additionally, we gained a deeper understanding of OpenAI’s API and how to structure outputs to create a meaningful learning experience.
## What we learned
Through this project, we learned a great deal about structured outputs, comprehension-based AI applications, and integrating AI-generated content seamlessly into existing text. We also gained insight into the complexities of front-end development and the importance of user experience in making an AI-powered tool truly effective.
## What's next for PMCExplainer
The next steps for PMCExplainer include a full revision and improvement of the AI-generated explanations, refining the comprehension assessment model, and developing a more user-friendly interface. Ultimately, the goal is to release an alpha version of the platform for testing and feedback, allowing researchers, students, and medical professionals to experience its benefits firsthand.
